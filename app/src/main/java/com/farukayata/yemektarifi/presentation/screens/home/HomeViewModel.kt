package com.farukayata.yemektarifi.presentation.screens.home


import android.content.ContentResolver
import android.graphics.Bitmap
import android.graphics.BitmapFactory
import android.net.Uri
import android.util.Base64
import android.util.Log
import androidx.lifecycle.ViewModel
import androidx.lifecycle.viewModelScope
import com.farukayata.yemektarifi.BuildConfig
import com.farukayata.yemektarifi.data.remote.OpenAiService
import com.farukayata.yemektarifi.data.remote.StorageRepository
import com.farukayata.yemektarifi.data.remote.VisionApiService
import com.farukayata.yemektarifi.data.remote.model.CategorizedItem
import com.farukayata.yemektarifi.data.remote.model.VisionRequest
import com.farukayata.yemektarifi.data.remote.model.VisionResponse
import dagger.hilt.android.lifecycle.HiltViewModel
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.RequestBody.Companion.toRequestBody
import java.io.ByteArrayOutputStream
import javax.inject.Inject

@HiltViewModel
class HomeViewModel @Inject constructor(
    private val visionApiService: VisionApiService,
//VisionApiService'Ä± constructor parametresi olarak aldÄ±k
    private val storageRepository: StorageRepository,
    private val openAiService: OpenAiService
) : ViewModel() {

    private val _selectedImageUri = MutableStateFlow<Uri?>(null)
    val selectedImageUri: StateFlow<Uri?> = _selectedImageUri

    private val _selectedImageBase64 = MutableStateFlow("")
    val selectedImageBase64: StateFlow<String> = _selectedImageBase64

    private val _detectedLabels = MutableStateFlow<List<VisionResponse.LabelAnnotation>>(emptyList())
    val detectedLabels: StateFlow<List<VisionResponse.LabelAnnotation>> = _detectedLabels

    private val _localizedObjects = MutableStateFlow<List<VisionRequest.LocalizedObjectAnnotation>>(emptyList())
    val localizedObjects: StateFlow<List<VisionRequest.LocalizedObjectAnnotation>> = _localizedObjects

    private val _openAiItems = MutableStateFlow<List<String>>(emptyList())
    val openAiItems: StateFlow<List<String>> = _openAiItems

    private val _categorizedItems = MutableStateFlow<List<CategorizedItem>>(emptyList())
    val categorizedItems: StateFlow<List<CategorizedItem>> = _categorizedItems



    fun setSelectedImage(uri: Uri?) {
        _selectedImageUri.value = uri
    }


    fun convertImageToBase64Compressed_2_1(uri: Uri?, contentResolver: ContentResolver) {
        uri?.let {
            try {
                val inputStream = contentResolver.openInputStream(uri)
                val bitmap = BitmapFactory.decodeStream(inputStream)
                inputStream?.close()

                //SÄ±kÄ±ÅŸtÄ±r
                val outputStream = ByteArrayOutputStream()
                bitmap.compress(Bitmap.CompressFormat.JPEG, 65, outputStream)
                val byteArray = outputStream.toByteArray()

                //GerÃ§ek JPEG byte dizisini Base64'e Ã§evir
                val base64String = Base64.encodeToString(byteArray, Base64.NO_WRAP)

                //Saf Base64'Ã¼ ata
                _selectedImageBase64.value = base64String

                Log.d("VisionRequestCheck", "Yeni Base64 uzunluÄŸu: ${base64String.length}")

            } catch (e: Exception) {
                e.printStackTrace()
                Log.e("VisionRequestCheck", "Hata oluÅŸtu: ${e.localizedMessage}")
            }
        }
    }



    fun analyzeWithOpenAi() {
        viewModelScope.launch(Dispatchers.IO) {
            //AÄŸ ve Base64 iÅŸlemleri ana thread yerine IO thread'de Ã§alÄ±ÅŸÄ±r
            //val imageUrl = _uploadedImageUrl.value ?: return@launch - storrage image kaydetmeyi saldÄ±k
            val base64 = _selectedImageBase64.value


            val json = """
            {
              "model": "gpt-4o",
              "messages": [
                {
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": "AÅŸaÄŸÄ±daki gÃ¶rselde yemek yapÄ±mÄ±nda kullanÄ±labilecek gÄ±da Ã¼rÃ¼nleri olabilir. GÃ¶rseli analiz et ve sadece yenilebilir, yemek yapÄ±mÄ±nda kullanÄ±lan Ã¼rÃ¼nleri aÅŸaÄŸÄ±daki formatta listele:\n\nðŸ… Domates - Sebzeler\nðŸ§€ Peynir - Yumurta ve SÃ¼t ÃœrÃ¼nleri\nðŸŸ Somon - BalÄ±k ve Deniz ÃœrÃ¼nleri\n\nLÃ¼tfen her satÄ±ra bir Ã¼rÃ¼n gelecek ÅŸekilde, yanÄ±na uygun bir emoji ve aÅŸaÄŸÄ±da belirtilen kategorilerden birini ekleyerek **TÃ¼rkÃ§e** yaz:\n\nEt ve Et ÃœrÃ¼nleri\nBalÄ±k ve Deniz ÃœrÃ¼nleri\nYumurta ve SÃ¼t ÃœrÃ¼nleri\nTahÄ±llar ve Unlu Mamuller\nBaklagiller\nSebzeler\nMeyveler\nBaharatlar ve Tat Vericiler\nYaÄŸlar ve SÄ±vÄ±lar\nKonserve ve HazÄ±r GÄ±dalar\nTatlÄ± Malzemeleri ve KuruyemiÅŸler\n\n**YalnÄ±zca bu kategori adlarÄ±nÄ±** kullan. marka isimleri veya tekrar eden benzer Ã¼rÃ¼nleri listeleme. Liste tekrarsÄ±z olsun."
                    },
                    {
                      "type": "image_url",
                      "image_url": {
                        "url": "data:image/jpeg;base64,$base64"
                      }
                    }
                  ]
                }
              ],
              "max_tokens": 500
            }
        """.trimIndent()

            val requestBody = json.toRequestBody("application/json".toMediaType())

            try {
                val response = openAiService.getImageAnalysis(requestBody)
                val result = response.choices.firstOrNull()?.message?.content
                val cleanedItems = result
                    ?.lines()
                    ?.mapNotNull { line ->
                        val parts = line.split(" - ")
                        if (parts.size == 2) {
                            val emojiAndName = parts[0].trim()
                            val category = parts[1].trim()

                            val emoji = emojiAndName.takeWhile { !it.isLetterOrDigit() }.trim()
                            val name = emojiAndName.dropWhile { !it.isLetterOrDigit() }.trim()

                            CategorizedItem(emoji, name, category)
                        } else null
                    } ?: emptyList()

                //_categorizedItems.value = cleanedItems
                //artÄ±k ui gÃ¼ncellemesini main thread de yapÄ±yoruz ÅŸu eklenti ile ;Dispatchers.io
                withContext(Dispatchers.Main) {
                    _categorizedItems.value = cleanedItems
                }

                /*-katagori de Ã§ekmeye baÅŸladÄ±k saldÄ±k burayÄ±
                val cleaned = result
                    ?.split(Regex("[\\n,â€¢-]"))
                    ?.mapNotNull { it.trim().removeSuffix(".").takeIf { it.isNotEmpty() } }
                    //?.mapNotNull { it.trim().takeIf { it.isNotEmpty() } }
                    ?: emptyList()

                _openAiItems.value = cleaned
                */

            } catch (e: Exception) {
                Log.e("OpenAI", "Hata: ${e.localizedMessage}")
            }
        }
    }



    fun detectLabels() {
        viewModelScope.launch {
            try {
                val base64Image = _selectedImageBase64.value
                if (base64Image.isNotEmpty()) {
                    val request = VisionRequest(
                        requests = listOf(
                            VisionRequest.Request(
                                image = VisionRequest.Image(content = base64Image),
                                features = listOf(
                                    VisionRequest.Feature()
                                ),
                                imageContext = VisionRequest.ImageContext(
                                    languageHints = listOf("en")
                                )
                            )
                        )
                    )
                    //data image mi deÄŸil mi prefixs
                    Log.d("VisionRequestCheck", "GÃ¶nderilecek Base64 ilk 100 karakter: ${base64Image.take(100)}")

                    Log.d("VisionRequestCheck", "Base64 uzunluÄŸu: ${base64Image.length}")
                    Log.d("VisionRequestCheck", "Request iÃ§eriÄŸi: $request")
                    val response = visionApiService.annotateImage(
                        apiKey = BuildConfig.VISION_API_KEY,
                        request = request
                    )
                    _detectedLabels.value = response.responses.firstOrNull()?.labelAnnotations ?: emptyList()

                    // BaÅŸarÄ±lÄ±ysa loga yazdÄ±ralÄ±m
                    response.responses.firstOrNull()?.labelAnnotations?.forEach { label ->
                        Log.d("VisionAPI", "Label: ${label.description} - Score: ${(label.score * 100).toInt()}%")
                    }
                }
            } catch (e: Exception) {
                e.printStackTrace()
                Log.e("VisionAPI", "Hata oluÅŸtu: ${e.message}")
            }
        }
    }

}

//Uri'den bitmap alÄ±yor â†’ JPEG'e sÄ±kÄ±ÅŸtÄ±rÄ±yor â†’ byteArray'e Ã§eviriyor â†’ Base64 encode ediyor

//vision api iÃ§in bu kÄ±sÄ±mÄ± update ettik;
/*
fun convertImageToBase64(uri: Uri?, contentResolver: ContentResolver) {
        uri?.let {
            val inputStream = contentResolver.openInputStream(uri)
            val bitmap = BitmapFactory.decodeStream(inputStream)
            inputStream?.close()

            val outputStream = ByteArrayOutputStream()
            bitmap.compress(Bitmap.CompressFormat.JPEG, 100, outputStream)
            val byteArray = outputStream.toByteArray()

            val base64String = android.util.Base64.encodeToString(byteArray, android.util.Base64.NO_WRAP)
            _selectedImageBase64.value = base64String
        }
    }
 */

//features ÅŸÃ¶yle de olabilir ;
/*
features = listOf(
                                VisionRequest.Feature(
                                    type = "LABEL_DETECTION",
                                    maxResults = 10
                                )
                            )
 */


/*
    fun convertImageToBase64(uri: Uri?, contentResolver: ContentResolver) {
        uri?.let {
            val inputStream = contentResolver.openInputStream(uri)
            val bitmap = BitmapFactory.decodeStream(inputStream)
            inputStream?.close()

            val outputStream = ByteArrayOutputStream()
            bitmap.compress(Bitmap.CompressFormat.JPEG, 80, outputStream) // %80 kalite sÄ±kÄ±ÅŸtÄ±rÄ±yoruz
            val byteArray = outputStream.toByteArray()

            val base64String = Base64.encodeToString(byteArray, Base64.NO_WRAP)
            _selectedImageBase64.value = base64String
        }
    }

    fun convertImageToBase64_2(uri: Uri?, contentResolver: ContentResolver) {
        uri?.let {
            val inputStream = contentResolver.openInputStream(uri)
            val bitmap = BitmapFactory.decodeStream(inputStream)
            inputStream?.close()

            // GÃ¶rseli yeniden boyutlandÄ±r: Ã¶rneÄŸin geniÅŸlik 600px yapalÄ±m
            val scaledBitmap = Bitmap.createScaledBitmap(
                bitmap,
                600, // hedef geniÅŸlik
                (bitmap.height * (600.0f / bitmap.width)).toInt(), // oranÄ± koru
                true
            )

            val outputStream = ByteArrayOutputStream()
            scaledBitmap.compress(Bitmap.CompressFormat.JPEG, 60, outputStream)
            // %60 kaliteyle sÄ±kÄ±ÅŸtÄ±rÄ±yoruz

            val byteArray = outputStream.toByteArray()
            val base64String = Base64.encodeToString(byteArray, Base64.NO_WRAP)
            _selectedImageBase64.value = base64String

            Log.d("VisionRequestCheck", "Yeni Base64 uzunluÄŸu: ${base64String.length}")
        }
    }

    fun convertImageToBase64Compressed(uri: Uri?, contentResolver: ContentResolver) {
        uri?.let {
            val inputStream = contentResolver.openInputStream(uri)
            val bitmap = BitmapFactory.decodeStream(inputStream)
            inputStream?.close()

            val outputStream = ByteArrayOutputStream()
            bitmap.compress(Bitmap.CompressFormat.JPEG, 60, outputStream)
            val byteArray = outputStream.toByteArray()

            val base64String = Base64.encodeToString(byteArray, Base64.NO_WRAP)

            // Base64 baÅŸÄ±na data:image/jpeg;base64, ekliyoruz!
            val fullBase64 = "data:image/jpeg;base64,$base64String"

            _selectedImageBase64.value = fullBase64

            Log.d("VisionRequestCheck", "Yeni Base64 uzunluÄŸu: ${fullBase64.length}")
        }
    }

    fun convertImageToBase64Compressed_2(uri: Uri?, contentResolver: ContentResolver) {
        uri?.let {
            val inputStream = contentResolver.openInputStream(uri)
            val bitmap = BitmapFactory.decodeStream(inputStream)
            inputStream?.close()

            val outputStream = ByteArrayOutputStream()
            bitmap.compress(Bitmap.CompressFormat.JPEG, 60, outputStream) // %60 kalite
            val byteArray = outputStream.toByteArray()

            val base64String = Base64.encodeToString(byteArray, Base64.NO_WRAP)

            _selectedImageBase64.value = base64String // SADECE Base64, baÅŸlÄ±k ekleme yok

            Log.d("VisionRequestCheck", "Yeni Base64 uzunluÄŸu: ${base64String.length}")
        }
    }

 */

    /*

    fun detectObjects() {
        viewModelScope.launch {
            try {
                val base64Image = _selectedImageBase64.value
                if (base64Image.isNotEmpty()) {
                    val request = VisionRequest(
                        requests = listOf(
                            VisionRequest.Request(
                                image = VisionRequest.Image(content = base64Image),
                                features = listOf(
                                    VisionRequest.Feature(
                                        type = "OBJECT_LOCALIZATION",
                                        maxResults = 20
                                    )
                                )
                            )
                        )
                    )

                    Log.d("VisionRequestCheck", "GÃ¶nderilecek Base64 ilk 100 karakter: ${base64Image.take(100)}")
                    Log.d("VisionRequestCheck", "Base64 uzunluÄŸu: ${base64Image.length}")
                    Log.d("VisionRequestCheck", "Request iÃ§eriÄŸi: $request")

                    val response = visionApiService.annotateImage(
                        apiKey = BuildConfig.VISION_API_KEY,
                        request = request
                    )

                    //val objects = response.responses.firstOrNull()?.localizedObjects ?: emptyList()
                    val objects = response.responses.firstOrNull()?.localizedObjectAnnotations ?: emptyList()

                    _localizedObjects.value = objects

                    objects.forEach {
                        Log.d("VisionAPI-Object", "Object: ${it.name} - Score: ${(it.score * 100).toInt()}%")
                    }
                }
            } catch (e: Exception) {
                e.printStackTrace()
                Log.e("VisionAPI", "Hata oluÅŸtu: ${e.message}")
            }
        }
    }

     */

    /*

        fun uploadImageToFirebase(uri: Uri) {
        viewModelScope.launch {
            try {
                val url = storageRepository.uploadImageAndGetUrl(uri)
                _uploadedImageUrl.value = url
                Log.d("FirebaseUpload", "Download URL: $url")
            } catch (e: Exception) {
                Log.e("FirebaseUpload", "Upload failed: ${e.message}")
            }
        }
    }

        private val _uploadedImageUrl = MutableStateFlow<String?>(null)
    val uploadedImageUrl: StateFlow<String?> = _uploadedImageUrl

     */